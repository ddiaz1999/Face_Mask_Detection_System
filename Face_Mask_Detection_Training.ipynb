{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Face_Mask_Detection_Training.ipynb",
      "provenance": [],
      "private_outputs": true,
      "collapsed_sections": [],
      "toc_visible": true,
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ddiaz1999/Face_Mask_Detection_System/blob/master/Face_Mask_Detection_Training.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BCl6OQpF_rNA"
      },
      "source": [
        "# <strong>Face Mask Detection</strong>\n",
        "\n",
        "*   **<font color='red'> Problema </font>** \n",
        "##### Detectar y clasificar la postura de una mascarilla sanitaria dentro de 3 clases.\n",
        "\n",
        "<br>\n",
        "<h6 align=center><b> ${\\text{Tabla 1. Clases}}$ </b><h6>\n",
        "\n",
        "|         ${\\text{Class}}$         |      ${\\text{Color Label}}$     |\n",
        "|:--------------------------------:|:-------------------------------:|\n",
        "|       ${\\text{with mask}}$       |  $\\color{green}{\\text{green}}$  |\n",
        "|     ${\\text{without mask}}$      |    $\\color{red}{\\text{red}}$    |\n",
        "| ${\\text{mask weared incorrect}}$ | $\\color{orange}{\\text{orange}}$ |\n",
        "<br>\n",
        "\n",
        "*   **<font color='red'> Dataset </font>** \n",
        "##### El *dataset* está disponible en [<font color='purple'><i>**Drive**<i></font>](https://drive.google.com/drive/folders/12LAZUHCMIR65BISzW_e7Yozbq8tAKcAQ?usp=sharing), este dataset es construido con otros datasets de dominio público:\n",
        "* [<font color='blue'><i>**Ver dataset 1**<i></font>](https://github.com/balajisrinivas/Face-Mask-Detection/tree/master/dataset)\n",
        "\n",
        "* [<font color='blue'><i>**Ver dataset 2**<i></font>](https://github.com/cabani/MaskedFace-Net)\n",
        "<br>\n",
        "\n",
        "---\n",
        "---\n",
        "\n",
        "#####Desarrollado por: \n",
        "<h6 align=center> ${\\text{Jhon Hader Fernández}}$ <h6>\n",
        "<h6 align=center> ${\\text{Diego Fernando Díaz}}$ <h6>\n",
        "<h6 align=center> ${\\text{Oscar Geovanny Baracaldo}}$ <h6>\n",
        "\n",
        "#####<h6 align=center>{<i>jhon_fernandez, di-diego, obaracaldo</i>}@javeriana.edu.co<h6>\n",
        "#####<h6 align=center>Pontificia Universidad Javeriana<h6>\n",
        "\n",
        "<br>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FJiwK1LMCxUv"
      },
      "source": [
        "## ***1. ENTORNO DE TRABAJO***\n",
        "\n",
        "Para el desarrollo del sistema se requiere de algunos paquetes, módulos, librerías externas y dispositivos de ejecución."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "G2Bu43taC57A"
      },
      "source": [
        "### ***1.1.  INSTALACIÓN DE PAQUETES EXTERNOS*** "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HEtxOT8A87kw"
      },
      "source": [
        "!pip install tensorflow"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "be3GhBaLC-eN"
      },
      "source": [
        "### ***1.2.  IMPORTAR PAQUETES Y LIBRERÍAS***\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RQY1zk3qsQM8"
      },
      "source": [
        "import tensorflow\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "from tensorflow.keras.applications import MobileNetV2\n",
        "from tensorflow.keras.layers import AveragePooling2D\n",
        "from tensorflow.keras.layers import Dropout\n",
        "from tensorflow.keras.layers import Flatten\n",
        "from tensorflow.keras.layers import Dense\n",
        "from tensorflow.keras.layers import Input\n",
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "from tensorflow.keras.applications.mobilenet_v2 import preprocess_input\n",
        "from tensorflow.keras.preprocessing.image import img_to_array\n",
        "from tensorflow.keras.preprocessing.image import load_img\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from sklearn.preprocessing import OneHotEncoder\n",
        "from sklearn.preprocessing import LabelBinarizer\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import classification_report\n",
        "from imutils import paths\n",
        "from IPython.display import clear_output\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import os"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HeT_H-JoDTsD"
      },
      "source": [
        "### ***1.3.  VERIFICAR EL DISPOSITIVO GPU***"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1KZJ-z_I8d9y"
      },
      "source": [
        "%tensorflow_version 2.x\n",
        "import tensorflow as tf\n",
        "device_name = tf.test.gpu_device_name()\n",
        "if device_name != '/device:GPU:0':\n",
        "  raise SystemError('GPU device not found, please check the device')\n",
        "print('Found GPU at: {}'.format(device_name))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "POckPbSkGUXn"
      },
      "source": [
        "## ***2. DATOS***\n",
        "\n",
        "Se debe cargar los datos, realizar un pequeño analisis y pre-procesamiento."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Uh2X7-rHGp9Y"
      },
      "source": [
        "### ***2.1.  OBTENER DATASET*** \n",
        "* **<font color='green'><i> 2.1.1. </i></font>** <br>\n",
        " El **dataset**  es cargado desde una carpeta de **<font color='magenta'> Google drive </font>** por ello se debe obtener la ruta de la carpeta, para ello se solicitará un permiso de acceso a **<font color='magenta'> Google drive </font>**\n",
        "\n",
        "* **<font color='green'><i> 2.1.2. </i></font>** <br>\n",
        " Se cargan todas las imagenes del conjunto de datos con su respectiva etiqueta, todas las imagenes son ajustadas a un tamaño de **<font color='blue'> `(224, 224)` </font>**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Xem1H5i8sRE1"
      },
      "source": [
        "# 2.1.1\n",
        "DIRECTORY  = '/content/drive/My Drive/Face Mask Detection/dataset'\n",
        "CATEGORIES  = ['mask_weared_incorrect', 'with_mask', 'without_mask']\n",
        "\n",
        "data = []\n",
        "labels = []\n",
        "i = 0\n",
        "\n",
        "# 2.1.2\n",
        "print(\"[INFO] loading images...\")\n",
        "for j, category in enumerate(CATEGORIES):\n",
        "\tpath = os.path.join(DIRECTORY, category)\n",
        "\tfor i, img in enumerate(os.listdir(path)):\n",
        "\t\tprint('[INFO] Folder', j+1, 'of 3:', category)\n",
        "\t\tprint('[INFO] Loading image', i+1, 'of', len(os.listdir(path)))\n",
        "\t\timg_path = os.path.join(path, img)\n",
        "\t\timage = load_img(img_path, target_size=(224, 224))\n",
        "\t\timage = img_to_array(image)\n",
        "\t\timage = preprocess_input(image)\n",
        "\n",
        "\t\tdata.append(image)\n",
        "\t\tlabels.append(category)\n",
        "\t\tclear_output(wait=True)\n",
        "\t\n",
        "print(\"[INFO] Images was loaded successfully!\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SJAr93LwHwtU"
      },
      "source": [
        "### ***2.2.  BALANCE*** \n",
        "Se obtiene el balance del conjunto de datos, esto permitirá descartar sobre ajustes en el entrenamiento del modelo."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9fkz9rLKIXdO"
      },
      "source": [
        "balance = {}\n",
        "\n",
        "for classes in CATEGORIES:\n",
        "  balance[classes] = labels.count(classes)\n",
        "  balance['% ' + classes] = (balance[classes] * 100.0) / len(labels)\n",
        "\n",
        "tags = 'with_mask', 'without_mask', 'mask_weared_incorrect'\n",
        "sizes = [balance['% with_mask'], balance['% without_mask'], balance['% mask_weared_incorrect']]\n",
        "colors = ['yellowgreen', 'crimson', 'orangered']\n",
        "explode = (0.05, 0.05, 0.05)\n",
        "\n",
        "fig, ax1 = plt.subplots(figsize = (18,9)) \n",
        "ax1.pie(sizes, explode=explode, colors=colors, startangle=90, autopct='%.1f%%', pctdistance=0.85, shadow = True, textprops=dict(fontsize=17)) \n",
        "plt.title('Data balance', fontsize=18, color='red') \n",
        "ax1.legend(tags, title=\"Classes\", loc='upper left', fontsize=12) \n",
        "plt.tight_layout() \n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dAPXNrgiHyeP"
      },
      "source": [
        "### ***2.3.  ONE HOT ENCONDING*** \n",
        "\n",
        "* **<font color='green'><i> 2.3.1. </i></font>** <br>\n",
        "Integer encoding\n",
        "\n",
        "* **<font color='green'><i> 2.3.2. </i></font>** <br>\n",
        "One Hot encoding"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ibc_Bw5wuAhI"
      },
      "source": [
        "# 2.3.1\n",
        "values = np.array(labels)\n",
        "label_encoder = LabelEncoder()\n",
        "integer_encoded = label_encoder.fit_transform(values)\n",
        "\n",
        "# 2.3.2\n",
        "onehot_encoder = OneHotEncoder(sparse=False)\n",
        "integer_encoded = integer_encoded.reshape(len(integer_encoded), 1)\n",
        "labels = onehot_encoder.fit_transform(integer_encoded)\n",
        "\n",
        "data = np.array(data, dtype=\"float32\")\n",
        "labels = np.array(labels)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NlEcZsSuLPpw"
      },
      "source": [
        "### ***2.4.  SEPARAR DATOS*** \n",
        "\n",
        "Se separa el conjunto de datos de la siguiente manera:\n",
        "\n",
        "| ${\\text{Data set}}$ | ${\\text{%}}$  |\n",
        "|:-------------------:|:-------------:|\n",
        "|   ${\\text{train}}$  | ${\\text{80}}$ |\n",
        "|   ${\\text{test}}$   | ${\\text{20}}$ |\n",
        "\n",
        "<br>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HVr-hN2zH9cW"
      },
      "source": [
        "(trainX, testX, trainY, testY) = train_test_split(data, labels, test_size=0.20, stratify=labels, random_state=42)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NnsRm27NNXfa"
      },
      "source": [
        "### ***2.5.  AUGMENTATION*** \n",
        "\n",
        "Esto permite aumentar la cantidad de datos: al tener un conjunto de datos de imágenes se realizan transformaciones geométricas; trasladar, rotar, invertir, escalar, zoom positivo y negativo, etc. Siempre manteniendo la etiqueta original."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "e0Ho7venOatu"
      },
      "source": [
        "aug = ImageDataGenerator(\n",
        "\trotation_range=20,\n",
        "\tzoom_range=0.15,\n",
        "\twidth_shift_range=0.2,\n",
        "\theight_shift_range=0.2,\n",
        "\tshear_range=0.15,\n",
        "\thorizontal_flip=True,\n",
        "\tfill_mode=\"nearest\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8FFecObPPNYb"
      },
      "source": [
        "## ***3. MODELO***\n",
        "\n",
        "Se construye y entrena el modelo."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ccmD5FuoPYsh"
      },
      "source": [
        "### ***3.1.  HIPER PARÁMETROS*** \n",
        "\n",
        "Se definen algunos hiper parámetros para el entrenamiento y desarrollo del modelo.\n",
        "\n",
        "| ${\\text{Hyper parameter}}$ | ${\\text{Variable}}$ |\n",
        "|:--------------------------:|:-------------------:|\n",
        "|  ${\\text{Learning rate}}$  |  ${\\text{INIT_LR}}$ |\n",
        "|   ${\\text{Batch size}}$    |     ${\\text{BS}}$   |\n",
        "|     ${\\text{Epochs}}$      |  ${\\text{EPOCHS}}$  |\n",
        "\n",
        "<br>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zvwvHsF3Qt66"
      },
      "source": [
        "INIT_LR = 1e-4          \n",
        "BS = 32           \n",
        "EPOCHS = 10"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yd8IrMm4Qwkd"
      },
      "source": [
        "### ***3.2.  CONSTRUCCIÓN*** \n",
        "\n",
        "A continuación se observa la arquitectura del modelo con sus respectivos parámetros y confguraciones.\n",
        "\n",
        "<br>\n",
        "\n",
        "![arch.PNG](https://drive.google.com/uc?id=1ALPJrPRSN2MAFT9lnYl6ta7IjrogfjI2)\n",
        "\n",
        "![arch1.PNG](https://drive.google.com/uc?id=1ynTxSdnK3veuN8KM9JviGho5br9_15VW)\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cm6a6WqiiTCA"
      },
      "source": [
        "baseModel = MobileNetV2(weights=\"imagenet\", include_top=False,\n",
        "\t\t\t\t\t\t\t\t\t\t\t\tinput_tensor=Input(shape=(224, 224, 3)))\n",
        "\n",
        "headModel = baseModel.output\n",
        "headModel = AveragePooling2D(pool_size=(7, 7))(headModel)\n",
        "headModel = Flatten(name=\"flatten\")(headModel)\n",
        "headModel = Dense(128, activation=\"relu\")(headModel)\n",
        "headModel = Dropout(0.5)(headModel)\n",
        "headModel = Dense(3, activation=\"softmax\")(headModel)\n",
        "\n",
        "# Crate model\n",
        "model = Model(inputs=baseModel.input, outputs=headModel)\n",
        "\n",
        "# Don't make fully conected the first layer\n",
        "for layer in baseModel.layers:\n",
        "\tlayer.trainable = False\n",
        "\n",
        "# Compile our model\n",
        "print(\"[INFO] compiling model...\")\n",
        "opt = Adam(lr=INIT_LR, decay=INIT_LR / EPOCHS)\n",
        "model.compile(loss=\"binary_crossentropy\", optimizer=opt, metrics=[\"accuracy\"])\n",
        "clear_output(wait=True)\n",
        "print(\"[REPORT] model was compiled successfully!\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pGRyhWgCZ2uU"
      },
      "source": [
        "### ***3.3.  ENTRENAMIENTO*** \n",
        "\n",
        "Se entrena el modelo sobre una GPU."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZQXVq72yaAvu"
      },
      "source": [
        "print(\"[INFO] training head...\")\n",
        "\n",
        "with tf.device('/device:GPU:0'):\n",
        "  H = model.fit(\n",
        "    aug.flow(trainX, trainY, batch_size=BS),\n",
        "    steps_per_epoch=len(trainX) // BS,\n",
        "    validation_data=(testX, testY),\n",
        "    validation_steps=len(testX) // BS,\n",
        "    epochs=EPOCHS)\n",
        "\n",
        "print(\"[REPORT] model was trained successfully!\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FD__G3twaO5g"
      },
      "source": [
        "### ***3.4.  EVALUACIÓN*** \n",
        "\n",
        "Se evalua el modelo implementado y se obtiene la precisión y la función de coste."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DXuaCSKV75ME"
      },
      "source": [
        "print(\"[INFO] evaluating network...\")\n",
        "# make predictions on the testing set\n",
        "predIdxs = model.predict(testX, batch_size=BS)\n",
        "\n",
        "# for each image in the testing set we need to find the index of the\n",
        "# label with corresponding largest predicted probability\n",
        "predIdxs = np.argmax(predIdxs, axis=1)\n",
        "\n",
        "# show a nicely formatted classification report\n",
        "print(classification_report(testY.argmax(axis=1), predIdxs,\n",
        "\ttarget_names=CATEGORIES))\n",
        "\n",
        "# plot the training loss and accuracy\n",
        "N = EPOCHS\n",
        "plt.style.use(\"ggplot\")\n",
        "plt.figure()\n",
        "plt.plot(np.arange(0, N), H.history[\"loss\"], label=\"train_loss\")\n",
        "plt.plot(np.arange(0, N), H.history[\"val_loss\"], label=\"val_loss\")\n",
        "plt.plot(np.arange(0, N), H.history[\"accuracy\"], label=\"train_acc\")\n",
        "plt.plot(np.arange(0, N), H.history[\"val_accuracy\"], label=\"val_acc\")\n",
        "plt.title(\"Training Loss and Accuracy\")\n",
        "plt.xlabel(\"Epoch #\")\n",
        "plt.ylabel(\"Loss/Accuracy\")\n",
        "plt.legend(loc=\"lower left\")\n",
        "\n",
        "performance_path = os.path.join('/content/drive/My Drive/Face Mask Detection/model', 'evaluation.png')\n",
        "plt.savefig(performance_path)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rPHrge71ag17"
      },
      "source": [
        "### ***3.4.  EXPORTAR MODELO*** \n",
        "\n",
        "Una vez el modelo es evaluado se exporta en formato **<font color='blue'> `.model` </font>** para ser usado como un modelo en cualquier otra aplicación."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mzXywMeiaMy7"
      },
      "source": [
        "print(\"[INFO] saving mask detector model...\")\n",
        "model_path = os.path.join('/content/drive/My Drive/Face Mask Detection/model', 'mask_detector.model')\n",
        "model.save(model_path, save_format=\"h5\")\n",
        "clear_output(wait=True)\n",
        "print(\"[INFO] model was saved successfully!\")"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}